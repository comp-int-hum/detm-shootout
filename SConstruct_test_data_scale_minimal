import os.path
from steamroller import Environment
from SCons.Environment import OverrideEnvironment

vars = Variables("custom_test_data_scale_minimal.py")
vars.AddVariables(
    ("OUTPUT_WIDTH", "", 5000),
    ("RANDOM_SEED", "", 0),
    ("DATA_ROOT", "", "temp_corpora"),
    ("MAX_SUBDOC_LENGTH", "", 100),
    ("MIN_WORD_COUNT", "", 10),
    ("MAX_WORD_PROPORTION", "", 0.7),
    ("TOP_NEIGHBORS", "", 15),
    ("TOP_TOPIC_WORDS", "", 5),
    ("TOPIC_COUNT", "", 50),
    ("MAX_EPOCHS", "", 100),
    ("CUDA_DEVICE", "", "cpu"),
    ("BATCH_SIZE", "", 512),
    ("LEARNING_RATE", "", 0.0001),
    ("LOWERCASE", "", True),
    (
        "TEST_PROPORTION",
        "",
        0.1
    ),
    (
        "VAL_PROPORTION",
        "This proportion of *non-test* data is used for validation (early stop etc)",
        0.1
    ),
    ("STUDIES", "", []),
    ("MODEL_TYPES", "", []),
    ("USE_WANDB", "", True),
    ("PROPORTIONS", "", [0.9, 0.8, 0.7, 0.6]),
    ("WORK_DIR", "", "work/proportions_minimal"),
    ("TRAINING_EVALUATION", "", True),
    ("EVAL_EVERY", "", 5)
)

env = Environment(
    variables=vars,
    BUILDERS={
        "SplitData" : Builder(
            action="python scripts/split_data.py --input ${SOURCES[0]} --first_output ${TARGETS[0]} --second_output ${TARGETS[1]} --second_proportion ${PROPORTION} --split_field ${SPLIT_FIELD} --random_seed ${RANDOM_SEED} --content_field ${CONTENT_FIELD} --down_sample ${DOWN_SAMPLE} --max_subdoc_length ${MAX_SUBDOC_LENGTH} ${'--lowercase' if LOWERCASE else ''}"
        ),
        "TrainEmbeddings" : Builder(
            action="python scripts/train_embeddings.py --input ${SOURCES[0]} --output ${TARGETS[0]} --content_field ${CONTENT_FIELD}"
        ),
        "TrainModel" : Builder(
            action="python scripts/train_model.py --train ${SOURCES[0]} ${'--val ' + VAL if VAL else ''} --embeddings ${SOURCES[1]} --window_size ${WINDOW_SIZE} --device ${CUDA_DEVICE} --batch_size ${BATCH_SIZE} --max_epochs ${MAX_EPOCHS} --output ${TARGETS[0]} --num_topics ${TOPIC_COUNT} --learning_rate ${LEARNING_RATE} --min_word_count ${MIN_WORD_COUNT} --max_word_proportion ${MAX_WORD_PROPORTION} --content_field ${CONTENT_FIELD} --time_field ${TIME_FIELD} --model_type ${MODEL_TYPE} --use_wandb ${USE_WANDB} ${'--word_list ' + WORD_LIST[0].rstr() if WORD_LIST else ''} ${'--training_evaluation' if TRAINING_EVALUATION else ''} ${'--eval_every ' + str(EVAL_EVERY) if TRAINING_EVALUATION else ''}"
        ),
        "ApplyModel" : Builder(
           action="python scripts/apply_model.py --model ${SOURCES[0]} --input ${SOURCES[1]} --device ${CUDA_DEVICE} --time_field ${TIME_FIELD} --content_field ${CONTENT_FIELD} --output ${TARGETS[0]}"
        ),
        "EvaluateModel" : Builder(
           action="python scripts/evaluate.py --model ${SOURCES[0]} --output ${TARGETS[0]} --embeddings ${SOURCES[1]} --reference_corpus ${SOURCES[2]}"
        ),
        "GenerateWordSimilarityTable" : Builder(
            action="python scripts/generate_word_similarity_table.py --embeddings ${SOURCES[0]} --output ${TARGETS[0]} --target_words ${WORD_SIMILARITY_TARGETS} --top_neighbors ${TOP_NEIGHBORS} ${'--language_code ' + LANGUAGE_CODE if LANGUAGE_CODE else ''}"
        ),
        "GenerateWordList" : Builder(
            action="python scripts/generate_word_list.py --output ${TARGETS[0]} --train ${SOURCES[0]} --min_word_count ${MIN_WORD_COUNT} --max_word_proportion ${MAX_WORD_PROPORTION} --content_field ${CONTENT_FIELD} --time_field ${TIME_FIELD} --random_seed ${RANDOM_SEED}"
        )
    }
)


max_downsample_value = max(env["PROPORTIONS"])

for study in env["STUDIES"]:
    env = OverrideEnvironment(env, study)

    original_data = "${DATA_ROOT}/${NAME}.jsonl.gz"
    data, test_data = env.SplitData(
        [
            "${WORK_DIR}/${NAME}/train_val_data.jsonl.gz",
            "${WORK_DIR}/${NAME}/test_data.jsonl.gz"
        ],
        original_data,
        PROPORTION=env["TEST_PROPORTION"],
        DOWN_SAMPLE=0.0
    )
    max_downsample, _ = env.SplitData(
            [
                "${WORK_DIR}/${NAME}/max_train_val_data.jsonl.gz",
                "${WORK_DIR}/${NAME}/max_unused_test_data.jsonl.gz"
            ],
            data,
            PROPORTION=env["TEST_PROPORTION"],
            DOWN_SAMPLE=max_downsample_value
        )
    
    word_list = env.GenerateWordList(
        "${WORK_DIR}/${NAME}/word_list.json",
        max_downsample
    )
    embeddings = env.TrainEmbeddings(
            "${WORK_DIR}/${NAME}/${DOWN_SAMPLE}_embeddings.bin.gz",
            data
        )
    word_similarity_table = env.GenerateWordSimilarityTable(
            "${WORK_DIR}/${NAME}/${DOWN_SAMPLE}_word_similarity.tex",
            embeddings,       
            TOP_NEIGHBORS=5,
        )
    
    for proportion in env["PROPORTIONS"]:
        study["DOWN_SAMPLE"] = proportion
        env = OverrideEnvironment(env, study)

        train_val_data, _ = env.SplitData(
            [
                "${WORK_DIR}/${NAME}/${DOWN_SAMPLE}_train_val_data.jsonl.gz",
                "${WORK_DIR}/${NAME}/${DOWN_SAMPLE}_unused_test_data.jsonl.gz"
            ],
            data,
            PROPORTION=env["TEST_PROPORTION"],
            DOWN_SAMPLE=proportion
        )
        for model_type in env["MODEL_TYPES"]:
            topic_model = env.TrainModel(
                "${WORK_DIR}/${NAME}/${MODEL_TYPE}_${DOWN_SAMPLE}_model.bin.gz",
                [
                    train_val_data,
                    embeddings,
                    word_list
                ],
                MODEL_TYPE=model_type,
                WORD_LIST=word_list
            )

            perplexity = env.ApplyModel(
                "${WORK_DIR}/${NAME}/${MODEL_TYPE}_${DOWN_SAMPLE}_perplexity.jsonl",
                [topic_model, test_data if test_data else train_val_data],
                MODEL_TYPE=model_type
            )

            evaluation = env.EvaluateModel(
                "${WORK_DIR}/${NAME}/${MODEL_TYPE}_${DOWN_SAMPLE}_evaluation.json",
                [topic_model, embeddings, test_data],
                MODEL_TYPE=model_type
            )

